# Code for paper: Contrasting Deep Learning Models for Direct Respiratory Insufficiency Detection Versus Blood Oxygen Saturation Estimation
This repository will host the codes used in the paper "Contrasting Deep Learning Models for Direct Respiratory Insufficiency Detection Versus Blood Oxygen Saturation Estimation". Any questions can be directed to marcelomatheusgauy@gmail.com.


# About the datasets
The SPIRA dataset used was collected in two phases (one of them can be found here: https://github.com/Edresson/SPIRA-ACL2021 and some extra audios here: https://zenodo.org/records/6672451). The first phase was collected in the peak of the pandemic (mid 2020). The second phase was collected after COVID-19 widespread vaccination. The data was collected in a few hospitals in Brazil. It consists of three utterances: 1) the sustained vowel 'aaaah', 2) a long and simple sentence ('o amor ao próximo ajuda a enfrentar o Coronavírus com a força que a gente precisa'), 3) a well-known nursery rhyme (usually, 'batatinha quando nasce...'). The data collected in hospitals consists of patients suffering from respiratory insufficiency. First phase data consists almost exclusively of COVID-19 patients. Second phase includes patients with respiratory insufficiency due to multiple causes, including COVID-19. In addition to the three audios, the dataset contains metadata including the following information: patient age and gender, blood oxygen saturation levels (at the time of recording), heart rate, and whether a mask was being used during recording. Additionally, as hospital ward noises are significant during recording, additional hospital ward noises were collected at the start of every recording session and are also part of the datasets. 


# About the models used
The paper uses 4 models: CNN6, CNN10, CNN14 from https://github.com/qiuqiangkong/audioset_tagging_cnn and Audio-MAE from https://github.com/facebookresearch/AudioMAE. The pretrained models can be found on the original repositories. We just finetune their pretrained models on the SPIRA datasets and make minor adaptations to the codebase so it can operate our files. The adaptations we made are included in folders PANNs (containing code for CNN6, CNN10, CNN14) and audio-mae. Essentially, we create functions to preprocess audios (add hospital ward noise if necessary, perform windowing as described in the paper and extract log-mel spectrograms), and finetune the pretrained models, replacing the final (classication) layer by a binary classification layer. This description applies to all 4 models and both respiratory insufficiency detection and high/low Spo2 threshold classification task. Both folders also contain code to run an SpO2 regression task that is not contained in the paper.

Credit on the models goes to the original creators (we include parts of their code here for completion and simplicity of the user to run the codes). Due to the sensitive nature of the data, the published datasets may differ slightly from the complete ones used in our models. Each folder should contain enough to run the models provided the paths to audio files and pretrained models are corrected. Further information is given in the respective folders.
